# 面试必备-操作系统知识

 原创  2015年08月20日 09:30:07

* 标签：
* [面试必备][0] /
* [操作系统篇][1] /


目录：

1. 进程的有哪几种状态，状态转换图，及导致转换的事件。

2. 进程与线程的区别。

3. 进程通信的几种方式。

4. 线程同步几种方式。

5. 线程的实现方式. (用户线程与内核线程的区别)

6. 用户态和核心态的区别。

7. 用户栈和内核栈的区别。

8. 内存池、进程池、线程池。

9. 死锁的概念，导致死锁的原因，导致死锁的四个必要条件，处理死锁的四个方式，预防死锁的方法、避免死锁的方法。

10. 进程调度算法。

11. Windows内存管理的方式(块式、页式、段式、段页式).

12. 内存连续分配方式采用的几种算法及各自优劣。

13. 动态链接及静态链接.

14. 基本分页、请求分页储存管理方式。

15. 基本分段、请求分段储存管理方式。

16. 分段分页方式的比较各自优缺点。

17. 几种页面置换算法，会算所需换页数。(LRU用程序如何实现？)

18. 虚拟内存的定义及实现方式。

19. 操作系统的四个特性。

20. DMA。

21. Spooling。

22. 外存分配的几种方式，及各种优劣。

 操作系统 是管理计算机硬件与软件资源的计算机程序，同时也是计算机系统的内核与基石。操作系统需要处理管理与配置内存、决定系统资源供需的优先次序、控制输入与输出设备、操作网络与管理文件系统等基本事务。操作系统也提供一个让 用户与系统交互的操作界面。

 操作系统上运行的计算机程序通常由一个或一组进程组成。因此，本文便从进程开始说起！

##  1. 进程的有哪几种状态，状态转换图，及导致转换的事件。 

 

[![1](http://zezhi.qiniudn.com/wp-content/uploads/2014/06/1.jpeg)](http://zezhi.qiniudn.com/wp-content/uploads/2014/06/1.jpeg "")

 如上图所示，进程包括三种状态：就绪态、运行态和阻塞态。详细说明如下：

 注意：创建和退出不是进程的状态。阻塞也叫等待， 等待 和就绪的区别：等待是等待除CPU以外的资源，而就绪等待的是CPU资源。

 1）就绪——执行：对就绪状态的进程，当进程调度程序按一种选定的策略从中选中一个就绪进程，为之分配了处理机后，该进程便由就绪状态变为执行状态；

   
 2）执行——等待：正在执行的进程因发生某等待事件而无法执行，则进程由执行状态变为等待状态，如进程提出输入/输出请求而变成等待外部设备传输信息的状态，进程申请资源（主存空间或外部设备）得不到满足时变成等待资源状态，进程运行中出现了故障（程序出错或主存储器读写错等）变成等待干预状态等等；

 3）等待——就绪：处于等待状态的进程，在其等待的事件已经发生，如输入/输出完成，资源得到满足或错误处理完毕时，处于等待状态的进程并不马上转入执行状态，而是先转入就绪状态，然后再由系统进程调度程序在适当的时候将该进程转为执行状态；

 4）执行——就绪：正在执行的进程，因时间片用完而被暂停执行，或在采用抢先式优先级调度算法的系统中,当有更高优先级的进程要运行而被迫让出处理机时，该进程便由执行状态转变为就绪状态。

##  2. 进程与线程的区别。 

进程可以认为是程序执行时的一个实例。进程是系统进行资源分配的独立实体， 且每个进程拥有独立的地址空间。一个进程无法直接访问另一个进程的变量和数据结构， 如果希望让一个进程访问另一个进程的资源，需要使用进程间通信，比如：管道，文件， 套接字等。

一个进程可以拥有多个线程，每个线程使用其所属进程的栈空间。 线程与进程的一个主要区别是，同一进程内的多个线程会共享部分状态， 多个线程可以读写同一块内存(一个进程无法直接访问另一进程的内存)。同时， 每个线程还拥有自己的寄存器和栈，其它线程可以读写这些栈内存。

线程是进程的一个特定执行路径。当一个线程修改了进程中的资源， 它的兄弟线程可以立即看到这种变化。

以下是分点小结：

1. 进程是系统进行资源分配的基本单位，有独立的内存地址空间； 线程是CPU调度的基本单位，没有单独地址空间，有独立的栈，局部变量，寄存器， 程序计数器等。
1. 创建进程的开销大，包括创建虚拟地址空间等需要大量系统资源； 创建线程开销小，基本上只有一个内核对象和一个堆栈。
1. 一个进程无法直接访问另一个进程的资源；同一进程内的多个线程共享进程的资源。
1. 进程切换开销大，线程切换开销小；进程间通信开销大，线程间通信开销小。
1. 线程属于进程，不能独立执行。每个进程至少要有一个线程，成为主线程
##  3. 进程通信的几种方式。 

 以 linux 操作系统为例 (window 也类似 ) ， linux 下进程间通信方式如下：

 1 管道（ Pipe ）及有名管道（ named pipe ）：管道可用于具有亲缘关系进程间的通信，有名管道克服了管道没有名字的限制，因此，除具有管道所具有的功能外，它还允许无亲缘关系进程间的通信；

 2 信号（ Signal ）：信号是比较复杂的通信方式，用于通知接受进程有某种事件发生，除了用于进程间通信外，进程还可以发送信号给进程本身； linux 除了支持 Unix 早期信号语义函数 sigal 外，还支持语义符合 Posix.1 标准的信号函数 sigaction （实际上，该函数是基于 BSD 的， BSD 为了实现可靠信号机制，又能够统一对外接口，用 sigaction 函数重新实现了 signal 函数）；

 3 报文（ Message ）队列（消息队列）：消息队列是消息的链接表，包括 Posix 消息队列 system V 消息队列。有足够权限的进程可以向队列中添加消息，被赋予读权限的进程则可以读走队列中的消息。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。

 4 共享内存：使得多个进程可以访问同一块内存空间，是最快的可用 IPC 形式。是针对其他通信机制运行效率较低而设计的。往往与其它通信机制，如信号量结合使用，来达到进程间的同步及互斥。

 5 信号量（ semaphore ）：主要作为进程间以及同一进程不同线程之间的同步手段。

 6 套接口（ Socket ）：更为一般的进程间通信机制，可用于不同机器之间的进程间通信。起初是由 Unix 系统的 BSD 分支开发出来的，但现在一般可以移植到其它类 Unix 系统上： Linux 和 System V 的变种都支持套接字。

##  4.线程同步几种方式。 

 线程同步的方式主要有以下四种 : 临界区（Critical Section）、互斥量（Mutex）、信号量（Semaphore）、事件（Event）的区别 。

 他们的主要区别和特点如下：

 1） 临界区：通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。在任意时刻只允许一个线程对共享资源进行访问，如果有多个线程试图访问公共资源，那么在有一个线程进入后，其他试图访问公共资源的线程将被挂起，并一直等到进入临界区的线程离开，临界区在被释放后，其他线程才可以抢占。   
 2 ） 互斥量：采用互斥对象机制。 只有拥有互斥对象的线程才有访问公共资源的权限，因为互斥对象只有一个，所以能保证公共资源不会同时被多个线程访问。互斥不仅能实现同一应用程序的公共资源安全共享，还能实现不同应用程序的公共资源安全共享   
 3 ） 信号量：它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目   
 4 ） 事 件： 通过通知操作的方式来保持线程的同步，还可以方便实现对多个线程的优先级比较的操作

##  5. 线程 的实现方式 . ( 换种方式说即： 用户线程与内核线程的区别 ) 

线程的实现可以分为两类：用户级线程(User-Level Thread)和内核线线程(Kernel-Level Thread)，后者又称为内核支持的线程或轻量级进程。在多线程操作系统中，各个系统的实现方式并不相同，在有的系统中实现了用户级线程，有的系统中实现了内核级线程。

用户线程指不需要内核支持而在用户程序中实现的线程，其不依赖于操作系统核心，应用进程利用线程库提供创建、同步、调度和管理线程的函数来控制用户线程。不需要用户态/核心态切换，速度快，操作系统内核不知道多线程的存在，因此一个线程阻塞将使得整个进程（包括它的所有线程）阻塞。由于这里的处理器时间片分配是以进程为基本单位，所以每个线程执行的时间相对减少。

内核线程：由操作系统内核创建和撤销。内核维护进程及线程的上下文信息以及线程切换。一个内核线程由于I/O操作而阻塞，不会影响其它线程的运行。

以下是用户级线程和内核级线程的区别：

1）内核支持线程是OS内核可感知的，而用户级线程是OS内核不可感知的。

2）用户级线程的创建、撤消和调度不需要OS内核的支持，是在语言（如Java）这一级处理的；而内核支持线程的创建、撤消和调度都需OS内核提供支持，而且与进程的创建、撤消和调度大体是相同的。

3）用户级线程执行系统调用指令时将导致其所属进程被中断，而内核支持线程执行系统调用指令时，只导致该线程被中断。

4）在只有用户级线程的系统内，CPU调度还是以进程为单位，处于运行状态的进程中的多个线程，由用户程序控制线程的轮换运行；在有内核支持线程的系统内，CPU调度则以线程为单位，由OS的线程调度程序负责线程的调度。

5）用户级线程的程序实体是运行在用户态下的程序，而内核支持线程的程序实体则是可以运行在任何状态下的程序。

## 6. 用户态和核心态的区别。

在讲述用户态和核心态的区别之前，我们先要说说“特权级”的概念。

熟悉Unix/Linux系统的人都知道，我们创建一个子进程时，是通过调用fork函数来实现的。事实上，fork的工作实际上是以系统调用的方式完成进程创建功能的，具体的工作是由sys_fork负责实施。对于任何操作系统来说，创建一个新的进程都是属于核心功能，因为它要做很多底层细致地工作，消耗系统的物理资源，比如分配物理内存，从父进程拷贝相关信息，拷贝设置页目录页表等等，这些显然不能随便让哪个程序就能去做，于是就自然引出特权级别的概念，显然，最关键性的权力必须由高特权级的程序来执行，这样才可以做到集中管理，减少有限资源的访问和使用冲突。

特权级显然是非常有效的管理和控制程序执行的手段，因此在硬件上对特权级做了很多支持，就Intel x86架构的CPU来说一共有0~3四个特权级，0级最高，3级最低，硬件上在执行每条指令时都会对指令所具有的特权级做相应的检查，相关的概念有CPL、DPL和RPL，这里不再过多阐述。硬件已经提供了一套特权级使用的相关机制，软件自然就是好好利用的问题，这属于操作系统要做的事情，对于Unix/Linux来说，只使用了0级特权级和3级特权级。也就是说在Unix/Linux系统中，一条工作在0级特权级的指令具有了CPU能提供的最高权力，而一条工作在3级特权级的指令具有CPU提供的最低或者说最基本权力。

OK，有了上面对“特权级”概念的了解，就能更直观的了解用户态和核心态的区别。内核态与用户态是操作系统的两种运行级别,，当程序运行在3级特权级上时，就可以称之为运行在用户态，因为这是最低特权级，是普通的用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态；反之，当程序运行在0级特权级上时，就可以称之为运行在内核态。运行在用户态下的程序不能直接访问操作系统内核数据结构和程序。当我们在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成某些它没有权力和能力完成的工作时就会切换到内核态。通常来说，以下三种情况会导致用户态到内核态的切换：

1）系统调用

这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如前例中fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。

2）异常

当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。

3）外围设备的中断

当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

这3种方式是系统在运行时由用户态转到内核态的最主要方式，其中系统调用可以认为是用户进程主动发起的，异常和外围设备中断则是被动的。

## 7. 用户栈和内核栈的区别。

操作系统中，每个进程会有两个栈，一个用户栈，存在于用户空间，一个内核栈，存在于内核空间。当进程在用户空间运行时，cpu堆栈指针寄存器里面的内容是用户堆栈地址，使用用户栈；当进程在内核空间时，cpu堆栈指针寄存器里面的内容是内核栈空间地址，使用内核栈。

内核栈是内存中属于操作系统空间的一块区域，其主要用途为：  
1)保存中断现场，对于嵌套中断，被中断程序的现场信息依次压入系统栈，中断返回时逆序弹出；

2)保存操作系统子程序间相互调用的参数、返回值、返回点以及子程序(函数)的局部变量。  
用户栈是用户进程空间中的一块区域，用于保存用户进程的子程序间相互调用的参数、返回值、返回点以及子程序(函数)的局部变量。

PS：那么为什么不直接用一个栈，何必浪费那么多的空间呢？ 1）如果只用系统栈。系统栈一般大小有限，如果中断有16个优先级，那么系统栈一般大小为15（只需保存15个低优先级的中断，另一个高优先级中断处理程序处于运行），但用户程序子程序调用次数可能很多，那样15次子程序调用以后的子程序调用的参数、返回值、返回点以及子程序(函数)的局部变量就不能被保存，用户程序也就无法正常运行了。

2）如果只用用户栈。我们知道系统程序需要在某种保护下运行，而用户栈在用户空间（即cpu处于用户态，而cpu处于核心态时是受保护的），不能提供相应的保护措施（或相当困难）。

## 8. 内存池、进程池、线程池。

首先介绍一个概念“池化技术 ”。池化技术 一言以蔽之就是：提前保存大量的资源，以备不时之需以及重复使用。池化技术应用广泛，如内存池，线程池，连接池等等。内存池相关的内容，建议看看Apache、Nginx等开源web服务器的内存池实现。

由于在实际应用当做，分配内存、创建进程、线程都会设计到一些系统调用，系统调用需要导致程序从用户态切换到内核态，是非常耗时的操作。因此，当程序中需要频繁的进行内存申请释放，进程、线程创建销毁等操作时，通常会使用内存池、进程池、线程池技术来提升程序的性能。

线程池：线程池的原理很简单，类似于操作系统中的缓冲区的概念，它的流程如下：先启动若干数量的线程，并让这些线程都处于睡眠状态，当需要一个开辟一个线程去做具体的工作时，就会唤醒线程池中的某一个睡眠线程，让它去做具体工作，当工作完成后，线程又处于睡眠状态，而不是将线程销毁。

进程池与线程池同理。

内存池：内存池是指程序预先从操作系统申请一块足够大内存，此后，当程序中需要申请内存的时候，不是直接向操作系统申请，而是直接从内存池中获取；同理，当程序释放内存的时候，并不真正将内存返回给操作系统，而是返回内存池。当程序退出(或者特定时间)时，内存池才将之前申请的真正内存释放。

## 9. 死锁的概念，导致死锁的原因，导致死锁的四个必要条件，预防死锁的方法、避免死锁的方法

计算机系统中,如果系统的资源分配策略不当，更常见的可能是程序员写的程序有错误等，则会导致进程因竞争资源不当而产生死锁的现象。

产生死锁的原因主要是：

1） 因为系统资源不足。

2） 进程运行推进的顺序不合适。

3） 资源分配不当等。

如果系统资源充足，进程的资源请求都能够得到满足，死锁出现的可能性就很低，否则就会因争夺有限的资源而陷入死锁。其次，进程运行推进顺序与速度不同，也可能产生死锁。

产生死锁的四个必要条件：

1） 互斥条件：一个资源每次只能被一个进程使用。

2） 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。

3） 不剥夺条件:进程已获得的资源，在末使用完之前，不能强行剥夺。

4） 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。

这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之一不满足，就不会发生死锁。

死锁的解除与预防：

理解了死锁的原因，尤其是产生死锁的四个必要条件，就可以最大可能地避免、预防和解除死锁。所以，在系统设计、进程调度等方面注意如何不让这四个必要条件成立，如何确定资源的合理分配算法，避免进程永久占据系统资源。

此外，也要防止进程在处于等待状态的情况下占用资源,在系统运行过程中，对进程发出的每一个系统能够满足的资源申请进行动态检查，并根据检查结果决定是否分配资源，若分配后系统可能发生死锁，则不予分配，否则予以分配 。因此，对资源的分配要给予合理的规划。

## 10. 进程调度算法。

几种进程调度算法：

一、先来先服务和短作业（进程）优先调度算法

1. 先来先服务调度算法。先来先服务（FCFS）调度算法是一种最简单的调度算法，该算法既可用于作业调度， 也可用于进程调度。FCFS算法比较有利于长作业（进程），而不利于短作业（进程）。由此可知，本算法适合于CPU繁忙型作业， 而不利于I/O繁忙型的作业（进程）。  
2. 短作业（进程）优先调度算法。短作业（进程）优先调度算法（SJ/PF）是指对短作业或短进程优先调度的算法，该算法既可用于作业调度， 也可用于进程调度。但其对长作业不利；不能保证紧迫性作业（进程）被及时处理；作业的长短只是被估算出来的。

二、高优先权优先调度算法

1. 优先权调度算法的类型。为了照顾紧迫性作业，使之进入系统后便获得优先处理，引入了最高优先权优先（FPF）调度算法。 此算法常被用在批处理系统中，作为作业调度算法，也作为多种操作系统中的进程调度，还可以用于实时系统中。当其用于作业调度， 将后备队列中若干个优先权最高的作业装入内存。当其用于进程调度时，把处理机分配给就绪队列中优先权最高的进程，此时， 又可以进一步把该算法分成以下两种：  
1)非抢占式优先权算法  
2)抢占式优先权调度算法（高性能计算机操作系统）  
2. 优先权类型 。对于最高优先权优先调度算法，其核心在于：它是使用静态优先权还是动态优先权， 以及如何确定进程的优先权。  
3. 高响应比优先调度算法  
为了弥补短作业优先算法的不足，我们引入动态优先权，使作业的优先等级随着等待时间的增加而以速率a提高。 该优先权变化规律可描述为：优先权=（等待时间+要求服务时间）/要求服务时间；即 =（响应时间）/要求服务时间

三、基于时间片的轮转调度算法

1. 时间片轮转法。时间片轮转法一般用于进程调度，每次调度，把CPU分配队首进程，并令其执行一个时间片。 当执行的时间片用完时，由一个记时器发出一个时钟中断请求，该进程被停止，并被送往就绪队列末尾；依次循环。

2. 多级反馈队列调度算法 多级反馈队列调度算法多级反馈队列调度算法，不必事先知道各种进程所需要执行的时间，它是目前被公认的一种较好的进程调度算法。 其实施过程如下：  
1) 设置多个就绪队列，并为各个队列赋予不同的优先级。在优先权越高的队列中， 为每个进程所规定的执行时间片就越小。  
2) 当一个新进程进入内存后，首先放入第一队列的末尾，按FCFS原则排队等候调度。 如果他能在一个时间片中完成，便可撤离；如果未完成，就转入第二队列的末尾，在同样等待调度…… 如此下去，当一个长作业（进程）从第一队列依次将到第n队列（最后队列）后，便按第n队列时间片轮转运行。  
3) 仅当第一队列空闲时，调度程序才调度第二队列中的进程运行；仅当第1到第（i-1）队列空时， 才会调度第i队列中的进程运行，并执行相应的时间片轮转。  
4) 如果处理机正在处理第i队列中某进程，又有新进程进入优先权较高的队列， 则此新队列抢占正在运行的处理机，并把正在运行的进程放在第i队列的队尾。

## 11. Windows内存管理的方式(块式、页式、段式、段页式).

块式管理

把主存分为一大块、一大块的，当所需的程序片断不在主存时就分配一块主存空间，把程序片断载入主存，就算所需的程序片度只有几个字节也只能把这一块分配给它。这样会造成很大的浪费，但时易于管理。

页式管理

把主存分为一页一页的，每一页的空间要比一块一块的空间小很多，显然这种方法的空间利用率要比块式管理高很多。

段式

把主存分为一段一段的，每一段的空间又要比一页一页的空间小很多，这种方法在空间利用率上又比页式管理高很多，但是也有另外一个缺点。一个程序片断可能会被分为几十段，这样很多时间就会被浪费在计算每一段的物理地址上（计算机最耗时间的大家都知道是I/O吧）。

段页式管理。(现在常用)

结合了段式管理和页式管理的优点。把主存分为若干页，每一页又分为若干段。

## 12. 内存连续分配方式采用的几种算法及各自优劣。

内存的连续分配方式有：单一连续分配、固定分区分配、动态分区分配以及动态重定位分区分配四种方式。  
单一连续分配：只能用于单用户、单任务的操作系统中。  
固定分区分配：可运行多道程序的存储管理方式。  
动态分区分配：根据进程的实际需要，动态地为之分配内存空间。  
可重定位分区分配：必须把一个系统或用户程序装入一连续的内存空间。

## 13. 动态链接及静态链接。

静态链接就是在编译链接时直接将需要的执行代码拷贝到调用处，优点就是在程序发布的时候就不需要的依赖库，也就是不再需要带着库一块发布，程序可以独立执行，但是体积可能会相对大一些。

动态链接就是在编译的时候不直接拷贝可执行代码，而是通过记录一系列符号和参数，在程序运行或加载时将这些信息传递给操作系统，操作系统负责将需要的动态库加载到内存中，然后程序在运行到指定的代码时，去共享执行内存中已经加载的动态库可执行代码，最终达到运行时连接的目的。优点是多个程序可以共享同一段代码，而不需要在磁盘上存储多个拷贝，缺点是由于是运行时加载，可能会影响程序的前期执行性能。

## 14. 基本分页、请求分页储存管理方式。

基本分页储存管理方式具有如下特征：

1) 一次性。要求将作业全部装入内存后方能运行。许多作业在每次运行时，并非其全部程序和数据都要用到。如果一次性地装入其全部程序，造成内存空间的浪费。

2) 驻留性。作业装入内存后，便一直驻留在内存中，直至作业运行结束。尽管运行中的进程会因I/O而长期等待，或有的程序模块在运行过一次后就不再需要(运行)了，但它们都仍将继续占用宝贵的内存资源。

请求分页储存管理是实现虚拟存储器的一种常用方式，它是在基本分页储存管理的基础上实现的。其基本思想是：在进程开始运行之前，仅装入当前要执行的部分页面即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的页面；当内存空间已满，而又需要装入新的页面时，者根据置换功能适当调出某个页面，以便腾出空间而装入新的页面。为实现请求分页，需要一定的硬件支持，包括：页表机制、缺页中断机构、地址变换机构。

## 15. 基本分段、请求分段储存管理方式。(略)

## 16. 分段分页方式的比较各自优缺点。

分段和分页其实都是一种对地址的划分或者映射的方式。 两者的区别主要有以下几点：

1)页是信息的物理单位，分页是为实现离散分配方式，以消减内存的外零头，提高内存的利用率；或者说，分页仅仅是由于系统管理的需要，而不是用户的需要（也是对用户透明的）。段是信息的逻辑单位，它含有一组其意义相对完整的信息（比如数据段、代码段和堆栈段等）。分段的目的是为了能更好的满足用户的需要（用户也是可以使用的）。

2)页的大小固定且由系统确定，把逻辑地址划分为页号和页内地址两部分，是由机器硬件实现的，因而一个系统只能有一种大小的页面。段的长度却不固定，决定于用户所编写的程序，通常由编辑程序在对源程序进行编辑时，根据信息的性质来划分。

3)分页的作业地址空间是维一的，即单一的线性空间，程序员只须利用一个记忆符（线性地址的16进制表示），即可表示一地址。分段的作业地址空间是二维的，程序员在标识一个地址时，既需给出段名（比如数据段、代码段和堆栈段等），又需给出段内地址。

4)页和段都有存储保护机制。但存取权限不同：段有读、写和执行三种权限；而页只有读和写两种权限。

## 17. 几种页面置换算法。

1）最佳置换算法（OPT）（理想置换算法）

这是一种理想情况下的页面置换算法，但实际上是不可能实现的。该算法的基本思想是：发生缺页时，有些页面在内存中，其中有一页将很快被访问（也包含紧接着的下一条指令的那页），而其他页面则可能要到10、100或者1000条指令后才会被访问，每个页面都可以用在该页面首次被访问前所要执行的指令数进行标记。最佳页面置换算法只是简单地规定：标记最大的页应该被置换。这个算法唯一的一个问题就是它无法实现。当缺页发生时，操作系统无法知道各个页面下一次是在什么时候被访问。虽然这个算法不可能实现，但是最佳页面置换算法可以用于对可实现算法的性能进行衡量比较。

2）先进先出置换算法（FIFO）

最简单的页面置换算法是先入先出（FIFO）法。这种算法的实质是，总是选择在主存中停留时间最长（即最老）的一页置换，即先进入内存的页，先退出内存。理由是：最早调入内存的页，其不再被使用的可能性比刚调入内存的可能性大。建立一个FIFO队列，收容所有在内存中的页。被置换页面总是在队列头上进行。当一个页面被放入内存时，就把它插在队尾上。  
这种算法只是在按线性顺序访问地址空间时才是理想的，否则效率不高。因为那些常被访问的页，往往在主存中也停留得最久，结果它们因变“老”而不得不被置换出去。  
FIFO的另一个缺点是，它有一种异常现象，即在增加存储块的情况下，反而使缺页中断率增加了。当然，导致这种异常现象的页面走向实际上是很少见的。

3）最近最久未使用（LRU）算法

FIFO算法和OPT算法之间的主要差别是，FIFO算法利用页面进入内存后的时间长短作为置换依据，而OPT算法的依据是将来使用页面的时间。如果以最近的过去作为不久将来的近似，那么就可以把过去最长一段时间里不曾被使用的页面置换掉。它的实质是，当需要置换一页时，选择在最近一段时间里最久没有使用过的页面予以置换。这种算法就称为最久未使用算法（Least Recently Used，LRU）。  
LRU算法是与每个页面最后使用的时间有关的。当必须置换一个页面时，LRU算法选择过去一段时间里最久未被使用的页面。

## 18. 虚拟内存的定义及实现方式。

虚拟内存是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存（例如RAM）的使用也更有效率。

## 19. 操作系统的四个特性。

1）并发（concurrence）  
并行性与并发性这两个概念是既相似又区别的两个概念。并行性是指两个或者多个事件在同一时刻发生，这是一个具有微观意义的概念，即在物理上这些事件是同时发生的；而并发性是指两个或者多个事件在同一时间的间隔内发生，它是一个较为宏观的概念。在多道程序环境下，并发性是指在一段时间内有多道程序在同时运行，但在单处理机的系统中，每一时刻仅能执行一道程序，故微观上这些程序是在交替执行的。 应当指出，通常的程序是静态实体，它们是不能并发执行的。为了使程序能并发执行，系统必须分别为每个程序建立进程。进程，又称任务，简单来说，是指在系统中能独立运行并作为资源分配的基本单位，它是一个活动的实体。多个进程之间可以并发执行和交换信息。一个进程在运行时需要运行时需要一定的资源，如 cpu,存储空间，及i/o设备等。在操作系统中引入进程的目的是使程序能并发执行。  
2）共享 (sharing)  
所谓共享是指，系统中的资源可供内存中多个并发执行的进程共同使用。由于资源的属性不同，故多个进程对资源的共享方式也不同，可以分为：互斥共享方式 和 同时访问方式  
3）虚拟 (virtual)  
是指通过技术吧一个物理实体变成若干个逻辑上的对应物。在操作系统中虚拟的实现主要是通过分时的使用方法。显然，如果n是某一个物理设备所对应的虚拟逻辑设备数，则虚拟设备的速度必然是物理设备速度的1/n。  
4）异步 (asynchronism)  
在多道程序设计环境下，允许多个进程并发执行，由于资源等因素的限制，通常，进程的执行并非“一气呵成”，而是以“走走停停”的方式运行。内存中每个进程在何时执行，何时暂停，以怎样的方式向前推进，每道程序总共需要多少时间才能完成，都是不可预知的。或者说，进程是以一步的方式运行的。尽管如此，但只要运行环境相同，作业经过多次运行，都会获得完全相同的结果。

## 20. DMA

直接存储器访问（Direct Memory Access，DMA）是计算机科学中的一种内存访问技术。它允许某些计算机内部的硬件子系统（电脑外设），可以独立地直接读写系统存储器，而不需绕道中央处理器（CPU）。在同等程度的处理器负担下，DMA是一种快速的数据传送方式。很多硬件的系统会使用DMA，包含硬盘控制器、绘图显卡、网卡和声卡。

## 21. Spooling

SPOOLing(即外部设备联机并行操作)，即Simultaneous Peripheral Operation On-Line的缩写，它是关于慢速字符设备如何与计算机主机交换信息的一种技术，通常称为“假脱机技术”。

## 22. 外存分配的几种方式，及其优劣。

1）连续分配

连续分配：创建文件时，分配一组连续的块；FAT中每个文件只要一项，说明起始块和文件的长度。对顺序文件有利。

优点:

简单。适用于一次性写入的操作

支持顺序存取和随机存取，顺序存取速度快

所需的磁盘寻道次数和寻道时间最少（因为由于空间的连续性，当访问下一个磁盘块时，一般无需移动磁头，当需要磁头移动，只需要移动一个磁道。

缺点:

文件不能动态增长（可能文件末尾处的空块已经分配给别的文件）

不利于文件插入和删除

外部碎片问题（反复增删文件后），使得很难找到空间大小足够的连续块。进行紧缩

在创建文件时声明文件的大小。

2）链式分配

链式分配：一个文件的信息存放在若干不连续的物理块中，各块之间通过指针连接，前一个物理块指向下一个物理块。FAT中每个文件同样只需要一项，包括文件名、起始块号和最后块号。任何一个自由块都可以加入到链中。

优点：

提高了磁盘空间利用率,不存在外部碎片问题

有利于文件插入和删除

有利于文件动态扩充

缺点：

存取速度慢，一般仅适于对信息的顺序存取，不适于随机存取:查找某一个块必须从头开始沿指针进行。

可靠性问题，如指针出错；更多的寻道次数和寻道时间

链接指针占用一定的空间，将多个块组成簇（cluster），按簇进行分配而不是按块进行分配（增加了磁盘碎片）。

3）索引分配

索引分配：每个文件在FAT中有一个一级索引，索引包含分配给文件的每个分区的入口。文件的索引保存在一个单独的块中。FAT中该文件的入口指向这一块。

优点：

保持了链接结构的优点,又解决了其缺点：按块分配可以消除外部碎片，按大小可变的分区分配可以提高局部性。索引分配支持顺序访问文件和直接访问文件，是普遍采用的一种方式。

满足了文件动态增长、插入删除的要求（只要有空闲块）

也能充分利用外存空间

缺点：

较多的寻道次数和寻道时间.

索引表本身带来了系统开销， 如：内外存空间，存取时间

[0]: http://so.csdn.net/so/search/s.do?q=面试必备&t=blog
[1]: http://so.csdn.net/so/search/s.do?q=操作系统篇&t=blog
[2]: http://write.blog.csdn.net/postedit/47803111